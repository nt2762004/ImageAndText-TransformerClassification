{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T11:10:08.134340Z",
     "iopub.status.busy": "2025-04-05T11:10:08.134048Z",
     "iopub.status.idle": "2025-04-05T11:10:11.492150Z",
     "shell.execute_reply": "2025-04-05T11:10:11.491256Z",
     "shell.execute_reply.started": "2025-04-05T11:10:08.134313Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "Number of GPUs: 1\n",
      "GPU Name: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "\n",
    "print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T11:10:11.493785Z",
     "iopub.status.busy": "2025-04-05T11:10:11.493403Z",
     "iopub.status.idle": "2025-04-05T11:10:15.909780Z",
     "shell.execute_reply": "2025-04-05T11:10:15.908791Z",
     "shell.execute_reply.started": "2025-04-05T11:10:11.493763Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext==0.6.0Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading torchtext-0.6.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nguye\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchtext==0.6.0) (4.66.4)\n",
      "Requirement already satisfied: requests in c:\\users\\nguye\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchtext==0.6.0) (2.32.3)\n",
      "Requirement already satisfied: torch in c:\\users\\nguye\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchtext==0.6.0) (2.5.1+cu121)\n",
      "Requirement already satisfied: numpy in c:\\users\\nguye\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchtext==0.6.0) (1.26.4)\n",
      "Requirement already satisfied: six in c:\\users\\nguye\\appdata\\roaming\\python\\python312\\site-packages (from torchtext==0.6.0) (1.16.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\nguye\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchtext==0.6.0) (0.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nguye\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->torchtext==0.6.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nguye\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->torchtext==0.6.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nguye\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->torchtext==0.6.0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nguye\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->torchtext==0.6.0) (2025.1.31)\n",
      "Requirement already satisfied: filelock in c:\\users\\nguye\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->torchtext==0.6.0) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\nguye\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->torchtext==0.6.0) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\nguye\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->torchtext==0.6.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nguye\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->torchtext==0.6.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\nguye\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->torchtext==0.6.0) (2024.5.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nguye\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->torchtext==0.6.0) (75.8.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\nguye\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->torchtext==0.6.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nguye\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch->torchtext==0.6.0) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nguye\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->torchtext==0.6.0) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nguye\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch->torchtext==0.6.0) (2.1.5)\n",
      "Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
      "Installing collected packages: torchtext\n",
      "Successfully installed torchtext-0.6.0\n"
     ]
    }
   ],
   "source": [
    "pip install torchtext==0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T11:10:15.911559Z",
     "iopub.status.busy": "2025-04-05T11:10:15.911318Z",
     "iopub.status.idle": "2025-04-05T11:10:18.227659Z",
     "shell.execute_reply": "2025-04-05T11:10:18.227010Z",
     "shell.execute_reply.started": "2025-04-05T11:10:15.911538Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from datasets import load_dataset\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import Vocab\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Thiết lập seed để đảm bảo tính tái lập\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T11:10:18.229162Z",
     "iopub.status.busy": "2025-04-05T11:10:18.228779Z",
     "iopub.status.idle": "2025-04-05T11:10:24.142347Z",
     "shell.execute_reply": "2025-04-05T11:10:24.141395Z",
     "shell.execute_reply.started": "2025-04-05T11:10:18.229130Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27 classes: ['Am nhac', 'Am thuc', 'Bat dong san', 'Bong da', 'Chung khoan', 'Cum ga', 'Cuoc song do day', 'Du hoc', 'Du lich', 'Duong vao WTO', 'Gia dinh', 'Giai tri tin hoc', 'Giao duc', 'Gioi tinh', 'Hackers va Virus', 'Hinh su', 'Khong gian song', 'Kinh doanh quoc te', 'Lam dep', 'Loi song', 'Mua sam', 'My thuat', 'San khau dien anh', 'San pham tin hoc moi', 'Tennis', 'The gioi tre', 'Thoi trang']\n",
      "Total samples: 14375\n",
      "Train samples: 11500\n",
      "Test samples: 2875\n"
     ]
    }
   ],
   "source": [
    "# Tải bộ dữ liệu TextData\n",
    "data_dir = 'TextData'\n",
    "classes = sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])\n",
    "label_map = {class_name: idx for idx, class_name in enumerate(classes)}\n",
    "\n",
    "print(f\"Found {len(classes)} classes: {classes}\")\n",
    "\n",
    "all_data = []\n",
    "for class_name in classes:\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    file_paths = glob.glob(os.path.join(class_dir, '*.txt'))\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-16') as f:\n",
    "                text = f.read().strip()\n",
    "                if text: # Đảm bảo văn bản không rỗng\n",
    "                    all_data.append((text, label_map[class_name]))\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "print(f\"Total samples: {len(all_data)}\")\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "train_data, test_data = train_test_split(all_data, test_size=0.2, random_state=42, stratify=[label for _, label in all_data])\n",
    "\n",
    "print(f\"Train samples: {len(train_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T11:10:24.143717Z",
     "iopub.status.busy": "2025-04-05T11:10:24.143365Z",
     "iopub.status.idle": "2025-04-05T11:10:27.659345Z",
     "shell.execute_reply": "2025-04-05T11:10:27.658692Z",
     "shell.execute_reply.started": "2025-04-05T11:10:24.143687Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tokenization và Từ vựng\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for text, _ in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "counter = Counter()\n",
    "for text, _ in train_data:\n",
    "    counter.update(tokenizer(text))\n",
    "\n",
    "# Tạo từ vựng\n",
    "vocab = Vocab(counter, specials=['<unk>', '<pad>'])\n",
    "\n",
    "# Ánh xạ các token đặc biệt sang chỉ số unk/pad\n",
    "UNK_IDX = vocab['<unk>']\n",
    "PAD_IDX = vocab['<pad>']\n",
    "\n",
    "# Hàm mã hóa\n",
    "MAX_LEN = 256\n",
    "\n",
    "def encode(text):\n",
    "    tokens = tokenizer(text)\n",
    "    ids = [vocab[token] if token in vocab.stoi else UNK_IDX for token in tokens][:MAX_LEN]\n",
    "    if len(ids) < MAX_LEN:\n",
    "        ids += [PAD_IDX] * (MAX_LEN - len(ids))\n",
    "    return ids\n",
    "\n",
    "# Dataset tùy chỉnh\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text, label = self.data[idx]\n",
    "        return torch.tensor(encode(text), dtype=torch.long), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "train_dataset = TextDataset(train_data)\n",
    "test_dataset = TextDataset(test_data)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T11:10:27.660280Z",
     "iopub.status.busy": "2025-04-05T11:10:27.660050Z",
     "iopub.status.idle": "2025-04-05T11:10:30.048013Z",
     "shell.execute_reply": "2025-04-05T11:10:30.047350Z",
     "shell.execute_reply.started": "2025-04-05T11:10:27.660261Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model with 27 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Mô hình Transformer Encoder\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, hidden_dim, num_layers, num_classes, dropout=0.1):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=PAD_IDX)\n",
    "        self.pos_embedding = nn.Embedding(MAX_LEN, embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim, \n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=hidden_dim, \n",
    "            dropout=dropout, \n",
    "            batch_first=True,\n",
    "            norm_first=True  # Chuẩn hóa trước lớp\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Attention pooling thay vì mean pooling\n",
    "        self.attention = nn.Linear(embed_dim, 1)\n",
    "        self.fc = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        padding_mask = (x == PAD_IDX)  # [batch_size, seq_len]\n",
    "        \n",
    "        positions = torch.arange(0, x.size(1), device=x.device).unsqueeze(0)\n",
    "        x = self.embedding(x) + self.pos_embedding(positions)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Transformer encoder với padding mask\n",
    "        x = self.transformer_encoder(x, src_key_padding_mask=padding_mask)\n",
    "        \n",
    "        # Attention pooling\n",
    "        attn_weights = torch.softmax(self.attention(x), dim=1)  # [batch_size, seq_len, 1]\n",
    "        x = torch.sum(x * attn_weights, dim=1)  # [batch_size, embed_dim]\n",
    "        \n",
    "        return self.fc(x)\n",
    "\n",
    "# Thiết lập mô hình\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_classes = len(classes)\n",
    "print(f\"Initializing model with {num_classes} classes.\")\n",
    "\n",
    "# Cải thiện: Giảm độ phức tạp mô hình và tăng regularization\n",
    "model = TransformerClassifier(\n",
    "    vocab_size=len(vocab),\n",
    "    embed_dim=256,\n",
    "    num_heads=4,\n",
    "    hidden_dim=512,\n",
    "    num_layers=2,       # Giảm từ 4 xuống 2 lớp để tránh overfitting trên tập dữ liệu nhỏ/vừa\n",
    "    num_classes=num_classes,\n",
    "    dropout=0.3         # Tăng dropout từ 0.2 lên 0.3\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Thêm weight_decay để phạt các trọng số lớn (L2 regularization)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T11:10:30.049288Z",
     "iopub.status.busy": "2025-04-05T11:10:30.048882Z",
     "iopub.status.idle": "2025-04-05T11:51:14.056217Z",
     "shell.execute_reply": "2025-04-05T11:51:14.055154Z",
     "shell.execute_reply.started": "2025-04-05T11:10:30.049267Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6886 - Test Loss: 1.0260 - Test Accuracy: 0.7009\n",
      "Saved best model to transformer_text_classification.pth\n",
      "\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8448 - Test Loss: 0.7632 - Test Accuracy: 0.7805\n",
      "Saved best model to transformer_text_classification.pth\n",
      "\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6568 - Test Loss: 0.6564 - Test Accuracy: 0.8024\n",
      "Saved best model to transformer_text_classification.pth\n",
      "\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5405 - Test Loss: 0.6504 - Test Accuracy: 0.8157\n",
      "Saved best model to transformer_text_classification.pth\n",
      "\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4715 - Test Loss: 0.6015 - Test Accuracy: 0.8254\n",
      "Saved best model to transformer_text_classification.pth\n",
      "\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4207 - Test Loss: 0.5680 - Test Accuracy: 0.8383\n",
      "Saved best model to transformer_text_classification.pth\n",
      "\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3644 - Test Loss: 0.6676 - Test Accuracy: 0.8261\n",
      "\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3369 - Test Loss: 0.6156 - Test Accuracy: 0.8358\n",
      "\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3030 - Test Loss: 0.6143 - Test Accuracy: 0.8393\n",
      "Saved best model to transformer_text_classification.pth\n",
      "\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2126 - Test Loss: 0.5690 - Test Accuracy: 0.8623\n",
      "Saved best model to transformer_text_classification.pth\n",
      "\n",
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1831 - Test Loss: 0.6059 - Test Accuracy: 0.8557\n",
      "\n",
      "Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1669 - Test Loss: 0.6359 - Test Accuracy: 0.8616\n",
      "\n",
      "Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1227 - Test Loss: 0.6239 - Test Accuracy: 0.8605\n",
      "Early stopping triggered!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Hàm huấn luyện\n",
    "def train(model, loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    loop = tqdm(loader, desc=\"Training\", leave=False)\n",
    "    for x, y in loop:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Hàm đánh giá\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    total_loss = 0\n",
    "    loop = tqdm(loader, desc=\"Evaluating\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for x, y in loop:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            total_loss += loss.item()\n",
    "            pred = out.argmax(dim=1)\n",
    "            preds.extend(pred.cpu().numpy())\n",
    "            targets.extend(y.cpu().numpy())\n",
    "    return total_loss / len(loader), accuracy_score(targets, preds)\n",
    "\n",
    "# Chạy huấn luyện với early stopping\n",
    "best_acc = 0\n",
    "patience = 3\n",
    "trigger_times = 0\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(30):\n",
    "    print(f\"\\nEpoch {epoch+1}\")\n",
    "    train_loss = train(model, train_loader)\n",
    "    test_loss, test_acc = evaluate(model, test_loader)\n",
    "    scheduler.step(test_loss)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    print(f\"Train Loss: {train_loss:.4f} - Test Loss: {test_loss:.4f} - Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        trigger_times = 0\n",
    "        torch.save(model.state_dict(), \"transformer_text_classification.pth\")\n",
    "        print(f\"Saved best model to transformer_text_classification.pth\")\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "        if trigger_times >= patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T11:52:11.265128Z",
     "iopub.status.busy": "2025-04-05T11:52:11.264844Z",
     "iopub.status.idle": "2025-04-05T11:52:11.269982Z",
     "shell.execute_reply": "2025-04-05T11:52:11.269082Z",
     "shell.execute_reply.started": "2025-04-05T11:52:11.265106Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "label_names = classes\n",
    "\n",
    "def predict_batch(text_list):\n",
    "    model.eval()\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for text in text_list:\n",
    "            encoded = encode(text)\n",
    "            tensor = torch.tensor(encoded, dtype=torch.long).unsqueeze(0).to(device)\n",
    "            output = model(tensor)\n",
    "            pred_idx = torch.argmax(output, dim=1).item()\n",
    "            pred_label = label_names[pred_idx]\n",
    "            results.append((text, pred_label))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T11:52:13.566231Z",
     "iopub.status.busy": "2025-04-05T11:52:13.565922Z",
     "iopub.status.idle": "2025-04-05T11:52:13.717301Z",
     "shell.execute_reply": "2025-04-05T11:52:13.716467Z",
     "shell.execute_reply.started": "2025-04-05T11:52:13.566204Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đội tuyển bóng đá Việt Nam đã giành chiến thắng thuyết phục trước đối thủ. -> [Bong da]\n",
      "Thị trường chứng khoán hôm nay ghi nhận mức tăng điểm kỷ lục. -> [Kinh doanh quoc te]\n",
      "Ca sĩ Mỹ Tâm vừa ra mắt album mới với nhiều ca khúc hit. -> [Am nhac]\n",
      "Giá vàng trong nước tiếp tục tăng cao do ảnh hưởng của thị trường thế giới. -> [Kinh doanh quoc te]\n",
      "Các nhà khoa học vừa phát hiện một loài động vật mới tại vườn quốc gia. -> [Giao duc]\n",
      "Bộ Giáo dục và Đào tạo công bố phương án thi tốt nghiệp THPT năm nay. -> [Giao duc]\n",
      "Du lịch Việt Nam đang thu hút ngày càng nhiều khách quốc tế. -> [Du lich]\n",
      "Công nghệ AI đang thay đổi cách chúng ta làm việc và sinh sống. -> [Gioi tinh]\n",
      "Món phở Hà Nội luôn là niềm tự hào của ẩm thực Việt Nam. -> [Am thuc]\n",
      "Tình hình giao thông tại các thành phố lớn đang ngày càng ùn tắc. -> [Kinh doanh quoc te]\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"transformer_text_classification.pth\", weights_only=True))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "vietnamese_samples = [\n",
    "    \"Đội tuyển bóng đá Việt Nam đã giành chiến thắng thuyết phục trước đối thủ.\",\n",
    "    \"Thị trường chứng khoán hôm nay ghi nhận mức tăng điểm kỷ lục.\",\n",
    "    \"Ca sĩ Mỹ Tâm vừa ra mắt album mới với nhiều ca khúc hit.\",\n",
    "    \"Giá vàng trong nước tiếp tục tăng cao do ảnh hưởng của thị trường thế giới.\",\n",
    "    \"Các nhà khoa học vừa phát hiện một loài động vật mới tại vườn quốc gia.\",\n",
    "    \"Bộ Giáo dục và Đào tạo công bố phương án thi tốt nghiệp THPT năm nay.\",\n",
    "    \"Du lịch Việt Nam đang thu hút ngày càng nhiều khách quốc tế.\",\n",
    "    \"Món phở Hà Nội luôn là niềm tự hào của ẩm thực Việt Nam.\",\n",
    "    \"Tình hình giao thông tại các thành phố lớn đang ngày càng ùn tắc.\"\n",
    "]\n",
    "\n",
    "predicted = predict_batch(vietnamese_samples)\n",
    "for text, label in predicted:\n",
    "    print(f\"{text} -> [{label}]\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
